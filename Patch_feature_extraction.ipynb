{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RADDINO Patch Feature Extraction Pipeline\n",
    "\n",
    "This notebook implements a medical image feature extraction pipeline designed to process chest X-rays from the SIIM-ACR Pneumothorax dataset. The core purpose is to extract deep learning features from these images using a pre-trained RADDINO model.\n",
    "\n",
    "## Key Components\n",
    "- Uses PyTorch and PyTorch Lightning for the deep learning framework\n",
    "- Employs MONAI (Medical Open Network for AI) for medical imaging-specific data handling\n",
    "- Implements efficient data processing with parallel execution and persistent caching\n",
    "- Configures a feature extraction model that outputs embeddings to a specified directory\n",
    "\n",
    "## Workflow\n",
    "The workflow follows a standard machine learning pipeline:\n",
    "1. Data loading from CSV files containing image paths\n",
    "2. Data transformation using specialized medical imaging preprocessing\n",
    "3. Dataset and dataloader configuration with persistent caching for performance\n",
    "4. Model initialization with appropriate parameters\n",
    "5. Validation through visual spot-checking of processed images\n",
    "6. Feature extraction execution using PyTorch Lightning's prediction mode\n",
    "\n",
    "The extracted features are saved to disk and can be used for downstream tasks such as classification, clustering, or further analysis. The notebook is optimized for performance with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import List\n",
    "from typing_extensions import override\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import monai as mn\n",
    "from transforms.Transform4RADDINO import Transform4RADDINO\n",
    "from models.RADDINO import Extractor_patch\n",
    "\n",
    "SEED = 5566\n",
    "pl.seed_everything(SEED)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict_part(df_part):\n",
    "    \"Important! Modify this function\"\n",
    "\n",
    "    BASE_PATH = '/MODIFY_THIS_PATH/' # modify\n",
    "    \n",
    "    data_dict = list()\n",
    "    for i in tqdm(range(len(df_part)), desc=\"Processing part\"):\n",
    "        row = df_part.iloc[i]\n",
    "\n",
    "        data_dict.append({\n",
    "            'img':BASE_PATH +'/'+ row[\"ImagePath\"],\n",
    "            \"paths\": BASE_PATH +'/'+ row[\"ImagePath\"]\n",
    "        })\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def get_data_dict(df, num_cores=32):\n",
    "    parts = np.array_split(df, num_cores)\n",
    "    func = partial(get_data_dict_part)\n",
    "    \n",
    "    with ProcessPoolExecutor(num_cores) as executor:\n",
    "        data_dicts = executor.map(func, parts)\n",
    "    \n",
    "    return list(itertools.chain(*data_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT BEFORE PROCEEDING --> DO YOU WANT TO DELETE CACHE???\n",
    "DELETE_CACHE = True\n",
    "\n",
    "INPUT = 'input_example.csv'\n",
    "\n",
    "TEST_NAME = '' \n",
    "MONAI_CACHE_DIR = f'./cache/{TEST_NAME}' \n",
    "IMG_SIZE = 518\n",
    "BATCH_SIZE = 16\n",
    "PRECISION = 'bf16-mixed' \n",
    "OUTPUT_FOLDER = './features_RADDINO/'\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5' ## set the GPU#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DELETE_CACHE:\n",
    "    if os.path.exists(MONAI_CACHE_DIR):\n",
    "        subprocess.call(['rm', '-rf', f'{MONAI_CACHE_DIR}'])\n",
    "        print(f\"MONAI's {MONAI_CACHE_DIR} cache directory removed successfully!\")\n",
    "    else:\n",
    "        print(f\"MONAI's {MONAI_CACHE_DIR} cache directory does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT).iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dict for datasets\n",
    "\n",
    "eval_dict = get_data_dict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "\n",
    "eval_transforms = Transform4RADDINO(IMG_SIZE).predict\n",
    "\n",
    "# define datasets\n",
    "\n",
    "eval_ds = mn.data.PersistentDataset(data=eval_dict, transform=eval_transforms, cache_dir=f\"{MONAI_CACHE_DIR}\")\n",
    "\n",
    "# define data loader\n",
    "\n",
    "eval_dl = DataLoader(eval_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=16, drop_last=False, persistent_workers=True)\n",
    "\n",
    "# instantiate the model\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "model = Extractor_patch(BATCH_SIZE=BATCH_SIZE, OUTPUT_DIR=OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot check the pre-processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPOT CHECK\n",
    "test_ds=mn.data.Dataset(data=eval_dict, transform=eval_transforms)\n",
    "\n",
    "for _ in range(3):\n",
    "    random_i = np.random.randint(0, len(test_ds))\n",
    "    for data_ in test_ds[random_i:random_i+1]:\n",
    "        \n",
    "        print(f\"{data_['paths']}\")\n",
    "        plt.imshow(np.array(data_['img'])[0,:,:], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_['img'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = RichProgressBar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate trainer\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[progress_bar], inference_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "_ = trainer.predict(model, dataloaders=eval_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siim-embd",
   "language": "python",
   "name": "siim-embd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
